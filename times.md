# DynoStore Benchmark CSV Fields

This document describes the fields generated by the benchmarking script.  
There are **two CSVs** produced:

- **Upload metrics** â†’ `--csv-upload`
- **Download metrics** â†’ `--csv-download`

---

## ðŸ“¤ Upload CSV (`bench_upload.csv`)

Each row corresponds to **one uploaded object** of a given size.

| Field | Description |
|-------|-------------|
| `op` | Operation type (always `"upload"` for this file). |
| `size_label` | Human-readable size string used in input (e.g., `"10MB"`, `"1GB"`). |
| `size_bytes` | Size of the payload in bytes. |
| `index` | Index of the object within this size group (0..N-1). |
| `key_object` | Unique key assigned to the uploaded object by DynoStore. |
| `pattern` | Payload generation pattern: `"zero"`, `"repeat"`, or `"urandom"`. |
| `encrypt` | `1` if encryption was enabled, `0` otherwise. |
| `resiliency` | Resiliency parameter passed to the client (number of replicas/EC level). |
| `local_upload_ms` | End-to-end upload time measured locally by the client (milliseconds). |
| `server_status` | Status reported in the serverâ€™s timeline (`"completed"`, `"failed"`, etc.). |
| `server_stream_ms` | Time spent streaming the object from client to server. |
| `server_catalog_ms` | Time to register metadata/catalog entry on the server. |
| `server_fragment_push_ms` | Time to push EC fragments to storage nodes. |
| `server_ec_ms` | Time spent splitting and encoding the object (erasure coding). |
| `servers_count` | Number of servers/storage nodes that received fragments. |
| `server[i].bytes` | Number of bytes written to server `i`. |
| `server[i].caching_ms` | Time server `i` spent updating its cache (ms). |
| `server[i].capacity` | Total capacity of server `i` (bytes). |
| `server[i].disk_write_time_ms` | Time to write fragment to disk on server `i` (ms). |
| `server[i].total_time_ms` | Total server-side time to process the fragment (ms). |
| `server[i].utilization` | Used capacity after writing the fragment. |

---

## ðŸ“¥ Download CSV (`bench_download.csv`)

Each row corresponds to **one download attempt** of a seeded object.  
For each size, one object is uploaded once, then downloaded N times.

| Field | Description |
|-------|-------------|
| `op` | Operation type (always `"download"` for this file). |
| `size_label` | Human-readable size string used in input (e.g., `"10MB"`, `"1GB"`). |
| `size_bytes` | Size of the seeded object in bytes. |
| `index` | Index of the download repetition (0..N-1). |
| `key_object` | Unique key of the seeded object being downloaded. |
| `pattern` | Payload generation pattern used when creating the seed object. |
| `encrypt` | `1` if encryption was enabled on upload, `0` otherwise. |
| `resiliency` | Resiliency parameter used when uploading the seed object. |
| `local_download_ms` | End-to-end download time measured locally by the client (milliseconds). |
| `downloaded_bytes` | Size of the downloaded object in bytes. |
| `server_pull_total_ms` | Total time for the server-side pull operation (from `pull_start` to `pull_end`). |
| `server_pull_metadata_ms` | Time to fetch metadata and routes for the object. |
| `server_pull_chunks_ms` | Time to retrieve object chunks from storage nodes. |
| `server_pull_reconstruct_ms` | Time to reconstruct the object (including erasure-code decoding if required). |
| `server_pull_cache_ms` | Time to cache the reconstructed object locally on the server. |

---

## Notes

- **Upload CSV** includes **per-server fragment metrics** (`server[i].*`).  
  The number of servers depends on your resiliency/EC configuration.
- **Download CSV** has **no per-server fields**, since it measures end-to-end retrieval.
- All time fields are in **milliseconds**, except capacity/utilization which are in **bytes**.
- `index` is:
  - **Upload CSV**: the object index (0..N-1).
  - **Download CSV**: the repetition index for downloading the same seeded object.
